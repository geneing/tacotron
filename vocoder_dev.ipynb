{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vocoder_dev.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/geneing/tacotron-1/blob/tacotron2-work-in-progress/vocoder_dev.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "tgPTbp-svPYI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "3a63b557-bd10-4c1c-c6c4-d90fbfc8a0fa"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "# http://pytorch.org/\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip3 install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.0-{platform}-linux_x86_64.whl torchvision\n",
        "\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "#print(torch.cuda.current_device())\n",
        "print(torch.cuda.get_device_name(0))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "Collecting torch==0.4.0 from http://download.pytorch.org/whl/cu80/torch-0.4.0-cp36-cp36m-linux_x86_64.whl\n",
            "\u001b[?25l  Downloading http://download.pytorch.org/whl/cu80/torch-0.4.0-cp36-cp36m-linux_x86_64.whl (484.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 484.0MB 50.4MB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x5b5a6000 @  0x7f3fea8101c4 0x46d6a4 0x5fcbcc 0x4c494d 0x54f3c4 0x553aaf 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54e4c8\n",
            "\u001b[?25hRequirement already up-to-date: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement not upgraded as not directly required: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.3)\n",
            "Requirement not upgraded as not directly required: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement not upgraded as not directly required: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.1.0)\n",
            "Installing collected packages: torch\n",
            "  Found existing installation: torch 0.4.0\n",
            "    Uninstalling torch-0.4.0:\n",
            "      Successfully uninstalled torch-0.4.0\n",
            "Successfully installed torch-0.4.0\n",
            "0.4.0\n",
            "Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pLFNAqKB_KNP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Upload full LJ dataset to google drive. Need to do this only once. Disabled by using magic %%script."
      ]
    },
    {
      "metadata": {
        "id": "Kw4TwL3-_RTh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip3 install -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iZfXfHZqpsdC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%script false\n",
        "!curl -O -L \"http://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\" \n",
        "fid = '170SC-OItkxCU536ikdRTDLW96z3Ho7CZ' #Collab Notebooks/Data \n",
        "upload = drive.CreateFile({\"parents\": [{\"kind\": \"drive#fileLink\", \"id\": fid}], 'title': 'LJSpeech-1.1.tar.bz2'})\n",
        "upload.SetContentFile('LJSpeech-1.1.tar.bz2')\n",
        "upload.Upload()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V6iplNKzidiR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Download Speech data."
      ]
    },
    {
      "metadata": {
        "id": "rdLm3Q8npcDg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3840fb62-db9c-43ef-b956-0124d3317a0a"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pydrive.drive.GoogleDrive at 0x7fcee4cc4828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "a5EjoQnUmh1O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def prep_archive(fid, fname):\n",
        "  import os\n",
        "  if not os.path.isfile('data/%s'%fname):  \n",
        "    dld = drive.CreateFile({'id': fid})\n",
        "    dld.GetContentFile(fname)\n",
        "    !mkdir -p data/LJSpeech\n",
        "    !mv {fname} data/\n",
        "\n",
        "  if not os.path.isdir('data/LJSpeech-1.1'): #not quite correct\n",
        "    !tar --strip-components 1 -xjf  data/{fname} -C data/LJSpeech\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VfYyeuXi6WXA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "#prep_archive(fid = '1EJdkZM2vhRy80ReHDwrbUB8wfsVJHBzW', fname='LJSpeech-1.1.tar.bz2') #full archive\n",
        "prep_archive(fid = '1DmkZ7rDIYf_JZiBZlVOvnXGxuSMTYqVv', fname='LJSpeech-1.1.tar.bz2') #100 wavs\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jdWyMRRXqz4C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "5cb89d46-d2db-476c-fac4-fb4149add00e"
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/geneing/tacotron-1.git tacotron\n",
        "!cd tacotron; git checkout tacotron2-work-in-progress; git pull; pip3 install -r requirements.txt\n",
        "!python3 tacotron/preprocess.py --dataset ljspeech --base_dir data/LJSpeech --output ../LJSpeech.taco\n",
        "\n"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'tacotron' already exists and is not an empty directory.\n",
            "Already on 'tacotron2-work-in-progress'\n",
            "Your branch is up-to-date with 'origin/tacotron2-work-in-progress'.\n",
            "Already up-to-date.\n",
            "Requirement already satisfied: falcon>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (1.4.1)\n",
            "Requirement already satisfied: inflect>=0.2.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (0.3.1)\n",
            "Requirement already satisfied: librosa>=0.5.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (0.6.1)\n",
            "Requirement already satisfied: matplotlib>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (2.1.2)\n",
            "Requirement already satisfied: numpy>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (1.14.3)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.11.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 9)) (4.23.4)\n",
            "Requirement already satisfied: Unidecode>=0.4.20 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 10)) (1.0.22)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from falcon>=1.2.0->-r requirements.txt (line 3)) (1.11.0)\n",
            "Requirement already satisfied: python-mimeparse>=1.5.2 in /usr/local/lib/python3.6/dist-packages (from falcon>=1.2.0->-r requirements.txt (line 3)) (1.6.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa>=0.5.1->-r requirements.txt (line 5)) (4.3.0)\n",
            "Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa>=0.5.1->-r requirements.txt (line 5)) (0.2.0)\n",
            "Requirement already satisfied: numba>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from librosa>=0.5.1->-r requirements.txt (line 5)) (0.38.0)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa>=0.5.1->-r requirements.txt (line 5)) (2.1.5)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa>=0.5.1->-r requirements.txt (line 5)) (0.19.1)\n",
            "Requirement already satisfied: joblib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from librosa>=0.5.1->-r requirements.txt (line 5)) (0.11)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.2->-r requirements.txt (line 6)) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.2->-r requirements.txt (line 6)) (2.5.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.2->-r requirements.txt (line 6)) (2.2.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.2->-r requirements.txt (line 6)) (2018.4)\n",
            "Requirement already satisfied: llvmlite>=0.23.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa>=0.5.1->-r requirements.txt (line 5)) (0.23.0)\n",
            "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
            "  from ._conv import register_converters as _register_converters\n",
            " 28%|████████████▏                              | 28/99 [00:09<00:23,  2.97it/s]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████████| 99/99 [00:29<00:00,  3.36it/s]\n",
            "Wrote 99 utterances, 52349 frames (0.18 hours)\n",
            "Max input length:  198906\n",
            "Max output length: 796\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LzXrw_uUTnco",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eb9fd8e7-f13d-499a-82e7-c672ba5a5ecc"
      },
      "cell_type": "code",
      "source": [
        "!ls /content/data/\n",
        "\n"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LJSpeech  LJSpeech-1.1.tar.bz2\tLJSpeech.taco\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MIXF3uiMDD1B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Now the actual work begins"
      ]
    },
    {
      "metadata": {
        "id": "BzGXQieyDInZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "class SpeechDataset(Dataset):\n",
        "    def __init__(self, root_dir):\n",
        "        self.root_dir = root_dir\n",
        "        self.metadata = pd.read_csv(os.path.join(self.root_dir, \"train.txt\"), sep='|', \n",
        "                                    header=None, names=['spec','mel','wav','mel_len','wav_len','text'])\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.metadata)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        sample = {}\n",
        "        wav_path=os.path.join(self.root_dir, self.metadata.wav[idx])\n",
        "        sample['text'] = self.metadata.text[idx]\n",
        "        sample['wav'] = np.load(wav_path)\n",
        "        return sample\n",
        "\n",
        "root_dir='data/LJSpeech.taco'\n",
        "ds = SpeechDataset(root_dir)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9eGungigmPMG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "quant = 256\n",
        "hidden_size = 896\n",
        "eye = np.eye(quant,dtype=np.float32)\n",
        "def mergeSamples(inp):\n",
        "    wavlist=[]\n",
        "    strlist=[]\n",
        "    for v in inp:\n",
        "        quantized = (((v['wav']+1.)/2.)*quant).astype(int)\n",
        "        \n",
        "        wavlist.append(quantized)\n",
        "        strlist.append(v['text'])\n",
        "    maxlen = max([x.shape[0] for x in wavlist])\n",
        "    \n",
        "    wavlist = np.asarray([  np.pad(x, ((0,maxlen-x.shape[0]),), 'constant') for x in wavlist])\n",
        "    return {'wav':wavlist.T, 'text':strlist}\n",
        "\n",
        "dl = DataLoader( ds, batch_size = 4, shuffle=True, collate_fn = mergeSamples )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "29MimDn1mbGm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "outputId": "af51ab6e-ad9b-42d0-fd15-da2e9b3a867b"
      },
      "cell_type": "code",
      "source": [
        "gru = torch.nn.GRUCell(quant, hidden_size).cuda()\n",
        "O1 = torch.nn.Linear(hidden_size, hidden_size//2).cuda()\n",
        "relu = torch.nn.ReLU().cuda()\n",
        "O2 = torch.nn.Linear(hidden_size//2, quant).cuda()\n",
        "\n",
        "params=[]\n",
        "for p in [gru, O1, O2]:\n",
        "    params += list(p.parameters()) \n",
        "\n",
        "optimizer = torch.optim.Adam(params, lr = 0.0001)\n",
        "\n",
        "for sample in dl:\n",
        "    wav = sample['wav']\n",
        "    h_rnn = torch.zeros([wav.shape[1], hidden_size]).cuda()\n",
        "    optimizer.zero_grad()\n",
        "    loss = 0\n",
        "    for i in range(min([1000,wav.shape[0]])):\n",
        "        coded_wav = torch.tensor(eye[ wav[i, :] ]).cuda()\n",
        "        h_rnn = gru(coded_wav, h_rnn)\n",
        "        o1 = relu(O1(h_rnn))\n",
        "        o2 = O2(o1)    \n",
        "        \n",
        "        loss += torch.nn.functional.cross_entropy(o2, torch.tensor(wav[i+1, :]).cuda())\n",
        "    print(loss)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    #break\n"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-105-38517ed330d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgru\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGRUCell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mO1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrelu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mO2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \"\"\"\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0;31m# Tensors stored in modules are graph leaves, and we don't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m                 \u001b[0;31m# want to create copy nodes, so we have to unpack the data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m                 \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                     \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \"\"\"\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (2) : out of memory at /pytorch/aten/src/THC/generic/THCStorage.cu:58"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "rz-ZEgEAoL7r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "566da9fc-9281-48db-cf4f-4c702e6dc48a"
      },
      "cell_type": "code",
      "source": [
        "torch.cuda.memory_cached()"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "318242816"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    }
  ]
}